{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fda886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "FACEMESH_POINTS = mp_face_mesh.FACEMESH_TESSELATION  # all triangulated connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d43be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACIAL_FEATURES = {\n",
    "    # Eyes (outline of left and right eyes)\n",
    "    \"left_eye\": [33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "                 173, 157, 158, 159, 160, 161, 246],\n",
    "    \"right_eye\": [263, 249, 390, 373, 374, 380, 381, 382,\n",
    "                  362, 398, 384, 385, 386, 387, 388, 466],\n",
    "\n",
    "    # Eyebrows\n",
    "    \"left_eyebrow\": [70, 63, 105, 66, 107, 55, 65, 52],\n",
    "    \"right_eyebrow\": [336, 296, 334, 293, 300, 276, 283, 282],\n",
    "\n",
    "    # Nose bridge and tip\n",
    "    \"nose\": [1, 2, 98, 327, 168, 197, 195, 5, 4, 45],\n",
    "    \"nose_bridge\": [6, 197, 195, 5, 4],\n",
    "    \"nose_tip\": [1, 2, 98, 327],\n",
    "\n",
    "    # Lips (outer and inner)\n",
    "    \"outer_lips\": [61, 146, 91, 181, 84, 17, 314, 405,\n",
    "                   321, 375, 291, 308, 324, 318, 402, 317, 14, 87],\n",
    "    \"inner_lips\": [78, 95, 88, 178, 87, 14, 317, 402,\n",
    "                   318, 324, 308, 291, 375, 321, 405, 314, 17, 84],\n",
    "\n",
    "    # Chin outline (jawline)\n",
    "    \"chin\": [152, 377, 400, 378, 379, 365, 397, 288,\n",
    "             435, 367, 397, 365, 379, 378, 400, 377, 152,\n",
    "             148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103],\n",
    "\n",
    "    # Ears\n",
    "    \"left_ear\": [234, 93, 132, 58, 172, 136],\n",
    "    \"right_ear\": [454, 323, 361, 288, 397, 365],\n",
    "\n",
    "    # Line between nose and lips (philtrum)\n",
    "    \"nose_to_lips\": [2, 164, 0, 37, 267, 13],\n",
    "\n",
    "    # Additional face outline (temple, jaw curve)\n",
    "    \"face_outline\": [10, 338, 297, 332, 284, 251, 389,\n",
    "                     356, 454, 323, 361, 288, 397, 365, 379,\n",
    "                     378, 400, 377, 152, 148, 176, 149, 150,\n",
    "                     136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109],\n",
    "\n",
    "    # Mid-eye centers (for eyeball placement)\n",
    "    \"left_eye_center\": [468],  # available if using iris model\n",
    "    \"right_eye_center\": [473],\n",
    "}\n",
    "EYEBALLS = {\n",
    "    \"left_iris\": [468, 469, 470, 471],\n",
    "    \"right_iris\": [473, 474, 475, 476],\n",
    "}\n",
    "import numpy as np\n",
    "\n",
    "def iris_center(iris_points, landmarks):\n",
    "    pts = np.array([[landmarks[i].x, landmarks[i].y] for i in iris_points])\n",
    "    return pts.mean(axis=0)\n",
    "import cv2\n",
    "\n",
    "def draw_feature(image, landmarks, feature_indices, color=(255,255,255), thickness=1):\n",
    "    points = [(int(landmarks[i].x * image.shape[1]),\n",
    "               int(landmarks[i].y * image.shape[0])) for i in feature_indices]\n",
    "    for i in range(len(points)-1):\n",
    "        cv2.line(image, points[i], points[i+1], color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "368f3861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760856941.733401 48421607 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n",
      "W0000 00:00:1760856941.734935 48456174 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760856941.739918 48456180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize FaceMesh model (refine_landmarks=True gives iris points)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('divija2.png')\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process image to get landmarks\n",
    "results = face_mesh.process(rgb_image)\n",
    "\n",
    "# ---------------------------\n",
    "# FACIAL FEATURE DICTIONARIES\n",
    "# ---------------------------\n",
    "\n",
    "FACIAL_FEATURES = {\n",
    "    # Eyes (outline of left and right eyes)\n",
    "    \"left_eye\": [33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "                 173, 157, 158, 470, 160, 161, 246],\n",
    "    \"right_eye\": [263, 249, 390, 373, 374, 380, 381, 382,\n",
    "                  362, 398, 384, 385, 475, 387, 388, 466],\n",
    "\n",
    "    # Eyebrows\n",
    "    \"left_eyebrow\": [70, 63, 105, 66, 107, 55, 65, 52, 53, 70],\n",
    "    \"right_eyebrow\": [336, 296, 334, 293, 300, 276, 283, 282],\n",
    "    \"top_eye\" : [414, 286, 258, 257, 259, 260, 467],  # upper eye contour\n",
    "    \"bottom_eye\" : [453, 452, 451, 450, 449, 448],  # lower eye contour\n",
    "    \"top_eye_left\": [190, 56, 28, 27, 29, 30, 247],\n",
    "    \"bottom_eye_left\": [228, 229, 230, 231, 232, 233],\n",
    "    # # Nose bridge and tip\n",
    "    # \"nose\": [1, 2, 98, 327, 168, 197, 195, 5, 4, 45],\n",
    "    # #\"nose_bridge\": [6, 197, 195, 5, 4],\n",
    "    # \"nose_tip\": [1, 2, 98, 327],\n",
    "    # Nose\n",
    "    # \"nose_bridge\": [6, 197, 195, 5, 4],\n",
    "    # \"nose_outline_left\": [98, 97, 2, 326],    # outer curve from bridge to nostril\n",
    "    # \"nose_outline_right\": [327, 326, 2, 97],  # mirror outline\n",
    "    # \"nostril_left\": [49, 50, 101, 118, 117],\n",
    "    # \"nostril_right\": [279, 278, 330, 347, 348],\n",
    "    # \"nose_bottom\": [97, 2, 326],  # base of nose\n",
    "\n",
    "    # Lips\n",
    "    \"outer_lips\": [61, 146, 91, 181, 84, 17, 314, 405,\n",
    "                   321, 375, 291, 308, 324, 318, 402,\n",
    "                   317, 14, 87, 178, 88, 95, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308],\n",
    "\n",
    "    \"inner_lips\": [78, 95, 88, 178, 87, 14, 317, 402,\n",
    "                   318, 324, 308, 291, 375, 321, 405, 314, 17, 84],\n",
    "\n",
    "    # Upper lip ridge (natural lip contour)\n",
    "    \"upper_lip\": [61, 40, 37, 0, 267, 270, 409, 291],\n",
    "\n",
    "    # Optional lower lip (for extra definition)\n",
    "    \"lower_lip\": [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291],\n",
    "\n",
    "    # Chin outline (jawline)\n",
    "    \"chin\": [58, 138, 172, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379],\n",
    "\n",
    "    # # Ears\n",
    "    # \"left_ear\": [234, 93, 132, 58, 172, 136],\n",
    "    # \"right_ear\": [454, 323, 361, 288, 397, 365],\n",
    "\n",
    "    # # Line between nose and lips (philtrum)\n",
    "    \"nose_to_lips_left\": [203, 206, 216, 57],\n",
    "    \"nose_to_lips_right\": [423, 426, 436, 287],\n",
    "    \n",
    "\n",
    "    # Mid-eye centers (for eyeball placement)\n",
    "    \"left_eye_center\": [468],  # available if using iris model\n",
    "    \"right_eye_center\": [473],\n",
    "}\n",
    "\n",
    "# Iris (eyeball) indices (only exist when refine_landmarks=True)\n",
    "EYEBALLS = {\n",
    "    \"left_iris\": [468, 469, 470, 471],\n",
    "    \"right_iris\": [473, 474, 475, 476],\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# DRAWING HELPERS\n",
    "# ---------------------------\n",
    "\n",
    "def draw_feature(image, landmarks, indices, color=(255, 255, 255), thickness=1):\n",
    "    \"\"\"Draw line features (eyes, lips, etc.)\"\"\"\n",
    "    points = [(int(landmarks[i].x * image.shape[1]),\n",
    "               int(landmarks[i].y * image.shape[0])) for i in indices]\n",
    "    for i in range(len(points) - 1):\n",
    "        cv2.line(image, points[i], points[i + 1], color, thickness)\n",
    "\n",
    "\n",
    "def draw_eyeball_clipped(image, landmarks, iris_indices, top_eyelid_indices, bottom_eyelid_indices, color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Draw eyeball circle clipped at eyelids.\n",
    "    - iris_indices: points of iris\n",
    "    - top_eyelid_indices: upper eyelid contour\n",
    "    - bottom_eyelid_indices: lower eyelid contour\n",
    "    \"\"\"\n",
    "    # Iris points\n",
    "    pts = np.array([[landmarks[i].x * image.shape[1], landmarks[i].y * image.shape[0]] \n",
    "                    for i in iris_indices])\n",
    "    center = np.mean(pts, axis=0)\n",
    "    radius = np.mean(np.linalg.norm(pts - center, axis=1))\n",
    "\n",
    "    # Eyelid bounds\n",
    "    top_pts = np.array([[landmarks[i].x * image.shape[1], landmarks[i].y * image.shape[0]] \n",
    "                        for i in top_eyelid_indices])\n",
    "    bottom_pts = np.array([[landmarks[i].x * image.shape[1], landmarks[i].y * image.shape[0]] \n",
    "                           for i in bottom_eyelid_indices])\n",
    "    y_top = np.min(top_pts[:, 1])\n",
    "    y_bottom = np.max(bottom_pts[:, 1])\n",
    "\n",
    "    # Draw circle as points only within eyelid bounds\n",
    "    num_points = 100\n",
    "    for theta in np.linspace(0, 2 * np.pi, num_points):\n",
    "        x = int(center[0] + radius * np.cos(theta))\n",
    "        y = int(center[1] + radius * np.sin(theta))\n",
    "        if y_top <= y <= y_bottom:\n",
    "            cv2.circle(image, (x, y), 1, color, 1)  # small point to draw outline\n",
    "\n",
    "    # Draw pupil at iris center\n",
    "    pupil_radius = int(radius * 0.3)\n",
    "    pupil_top = max(int(center[1] - pupil_radius), int(y_top))\n",
    "    pupil_bottom = min(int(center[1] + pupil_radius), int(y_bottom))\n",
    "    for y in range(pupil_top, pupil_bottom):\n",
    "        for x in range(int(center[0] - pupil_radius), int(center[0] + pupil_radius)):\n",
    "            if (x - center[0])**2 + (y - center[1])**2 <= pupil_radius**2:\n",
    "                image[y, x] = color\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN LOGIC\n",
    "# ---------------------------\n",
    "\n",
    "if results.multi_face_landmarks:\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        # Draw facial line features\n",
    "        for name, indices in FACIAL_FEATURES.items():\n",
    "            draw_feature(image, face_landmarks.landmark, indices)\n",
    "\n",
    "        for iris_name, iris_indices in EYEBALLS.items():\n",
    "            if \"left\" in iris_name:\n",
    "                draw_eyeball_clipped(image, face_landmarks.landmark, iris_indices,\n",
    "                             FACIAL_FEATURES[\"top_eye_left\"], FACIAL_FEATURES[\"bottom_eye_left\"])\n",
    "            else:\n",
    "                draw_eyeball_clipped(image, face_landmarks.landmark, iris_indices,\n",
    "                             FACIAL_FEATURES[\"top_eye\"], FACIAL_FEATURES[\"bottom_eye\"])\n",
    "\n",
    "# Show output\n",
    "cv2.imwrite(\"face.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a1db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: divija_dhall.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760897963.864063 48421607 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n",
      "W0000 00:00:1760897963.866233 48889342 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760897963.874838 48889340 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1760897963.887492 48421607 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n",
      "W0000 00:00:1760897963.889377 48889354 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1760897963.942955 48421607 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n",
      "W0000 00:00:1760897963.945917 48889365 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved simplified line drawing to: selective_line_drawing_simplified_divija_dhall.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import scipy.ndimage\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "\n",
    "HAIR_MODEL_PATH = '/Users/divija/Divi Drive/workplace/Princeton/Sem 5/Carlab/carlab_2025/final_project/hair_segmenter.tflite'\n",
    "\n",
    "# ---------------------------\n",
    "# Simplified Facial Feature Dictionaries\n",
    "# ---------------------------\n",
    "\n",
    "FACIAL_FEATURES = {\n",
    "    # Eyes (outline of left and right eyes)\n",
    "    \"left_eye\": [33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "                 173, 157, 158, 470, 160, 161, 246],\n",
    "    \"right_eye\": [263, 249, 390, 373, 374, 380, 381, 382,\n",
    "                  362, 398, 384, 385, 475, 387, 388, 466],\n",
    "\n",
    "    # Eyebrows\n",
    "    \"left_eyebrow\": [70, 63, 105, 66, 107, 55, 65, 52, 53, 70],\n",
    "    \"right_eyebrow\": [336, 296, 334, 293, 300, 276, 283, 282, 295, 285, 336],\n",
    "\n",
    "    # Upper / lower eyelid contours for clipped eyeballs\n",
    "    \"top_eye\": [414, 286, 258, 257, 259, 260, 467],\n",
    "    \"bottom_eye\": [453, 452, 451, 450, 449, 448],\n",
    "    \"top_eye_left\": [190, 56, 28, 27, 29, 30, 247],\n",
    "    \"bottom_eye_left\": [228, 229, 230, 231, 232, 233],\n",
    "\n",
    "    # Lips\n",
    "    \"outer_lips\": [61, 146, 91, 181, 84, 17, 314, 405,\n",
    "                   321, 375, 291, 308, 324, 318, 402,\n",
    "                   317, 14, 87, 178, 88, 95, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308],\n",
    "    \"inner_lips\": [78, 95, 88, 178, 87, 14, 317, 402,\n",
    "                   318, 324, 308, 291, 375, 321, 405, 314, 17, 84],\n",
    "    \"upper_lip\": [61, 40, 37, 0, 267, 270, 409, 291],\n",
    "    \"lower_lip\": [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291],\n",
    "\n",
    "    # Chin / jawline\n",
    "    \"chin\": [58, 138, 172, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379],\n",
    "    # actual nose:\n",
    "    \"nose_left\": [122, 196, 236, 198, 209, 49, 48, 64, 98],\n",
    "    \"nose_right\": [420, 360, 278, 294, 327, 326],\n",
    "    \"nostrils_left\" : [98, 240, 75, 60, 99, 97],\n",
    "    \"nostrils_right\" : [370, 354, 458, 290],\n",
    "    \"nose_center\": [238, 241,242,370, 354, 94],\n",
    "    # Nose to lips (philtrum)\n",
    "    \"nose_to_lips_left\": [203, 206, 216, 57],\n",
    "    \"nose_to_lips_right\": [423, 426, 436, 287],\n",
    "\n",
    "    # Mid-eye centers for eyeball placement\n",
    "    \"left_eye_center\": [468],\n",
    "    \"right_eye_center\": [473],\n",
    "}   \n",
    "\n",
    "# Iris (eyeball) indices\n",
    "EYEBALLS = {\n",
    "    \"left_iris\": [468, 469, 470, 471],\n",
    "    \"right_iris\": [473, 474, 475, 476],\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Drawing helpers\n",
    "# ---------------------------\n",
    "\n",
    "def smooth_points(points, sigma=5):\n",
    "    \"\"\"\n",
    "    Smooth a list of points using Gaussian smoothing independently on x and y.\n",
    "    points: list of (x, y)\n",
    "    sigma: Gaussian kernel standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    points = np.array(points, dtype=np.float32)\n",
    "    x_smooth = scipy.ndimage.gaussian_filter1d(points[:, 0], sigma=sigma)\n",
    "    y_smooth = scipy.ndimage.gaussian_filter1d(points[:, 1], sigma=sigma)\n",
    "    return list(zip(x_smooth.astype(int), y_smooth.astype(int)))\n",
    "def draw_feature(image, landmarks, indices, color=(255, 255, 255), thickness=2, smooth=True):\n",
    "    points = [(int(landmarks[i].x * image.shape[1]),\n",
    "               int(landmarks[i].y * image.shape[0])) for i in indices]\n",
    "    if smooth and len(points) >= 3:\n",
    "        points = smooth_points(points, sigma=0.1)\n",
    "    for i in range(len(points) - 1):\n",
    "        cv2.line(image, points[i], points[i + 1], color, thickness)\n",
    "\n",
    "def draw_eyeball_clipped(image, landmarks, iris_indices, top_eyelid_index, bottom_eyelid_index, color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Draw an eyeball circle clipped at the top eyelid landmark.\n",
    "    - iris_indices: list of iris landmarks\n",
    "    - top_eyelid_index: single landmark index for upper eyelid to clip at\n",
    "    - bottom_eyelid_indices: list of lower eyelid landmarks\n",
    "    \"\"\"\n",
    "    H, W = image.shape[:2]\n",
    "    \n",
    "    # Iris points\n",
    "    pts = np.array([[landmarks[i].x * W, landmarks[i].y * H] for i in iris_indices])\n",
    "    center = np.mean(pts, axis=0)\n",
    "    radius = np.mean(np.linalg.norm(pts - center, axis=1))\n",
    "    \n",
    "    # Upper eyelid landmark coordinate\n",
    "    upper_y = landmarks[top_eyelid_index].y * H\n",
    "\n",
    "    # Bottom eyelid bounds\n",
    "    bottom_y = np.array([landmarks[bottom_eyelid_index].y * H])\n",
    "    y_bottom = np.max(bottom_y)\n",
    "    \n",
    "    # Draw circle outline, skip points above upper eyelid landmark\n",
    "    num_points = 200\n",
    "    for theta in np.linspace(0, 2*np.pi, num_points):\n",
    "        x = int(center[0] + radius * np.cos(theta))\n",
    "        y = int(center[1] + radius * np.sin(theta))\n",
    "        if upper_y <= y <= y_bottom:\n",
    "            cv2.circle(image, (x, y), 1, color, 1)\n",
    "    \n",
    "    # Draw pupil clipped at the same bounds\n",
    "    pupil_radius = int(radius * 0.3)\n",
    "    pupil_top = max(int(center[1] - pupil_radius), int(upper_y))\n",
    "    pupil_bottom = min(int(center[1] + pupil_radius), int(y_bottom))\n",
    "    \n",
    "    for y in range(pupil_top, pupil_bottom):\n",
    "        for x in range(int(center[0] - pupil_radius), int(center[0] + pupil_radius)):\n",
    "            if (x - center[0])**2 + (y - center[1])**2 <= pupil_radius**2:\n",
    "                image[y, x] = color\n",
    "# ---------------------------\n",
    "# Main selective line drawing\n",
    "# ---------------------------\n",
    "\n",
    "def image_to_minimal_line_drawing_simplified(image_path, output_path):\n",
    "    print(f\"Processing: {image_path}\")\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"Error: Image not found.\")\n",
    "        return\n",
    "    H, W, _ = img.shape\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    final_line_drawing = np.ones((H, W), dtype=np.uint8) * 255\n",
    "\n",
    "    # FaceMesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as face_mesh:\n",
    "        results_face = face_mesh.process(img_rgb)\n",
    "        if results_face.multi_face_landmarks:\n",
    "            face_landmarks = results_face.multi_face_landmarks[0]\n",
    "\n",
    "    # Draw simplified facial features on final_line_drawing\n",
    "    for name, indices in FACIAL_FEATURES.items():\n",
    "        if \"left_eye_center\" in name or \"right_eye_center\" in name:\n",
    "            continue\n",
    "        draw_feature(final_line_drawing, face_landmarks.landmark, indices, color=0, thickness=2)\n",
    "\n",
    "    # Draw clipped eyeballs on final_line_drawing\n",
    "    for iris_name, iris_indices in EYEBALLS.items():\n",
    "        if \"left\" in iris_name:\n",
    "            draw_eyeball_clipped(final_line_drawing, face_landmarks.landmark, iris_indices,\n",
    "                                160, 145, color=0)\n",
    "        else:\n",
    "            draw_eyeball_clipped(final_line_drawing, face_landmarks.landmark, iris_indices,\n",
    "                                385, 374, color=0)\n",
    "\n",
    "    # Selfie Segmentation for hair/body outline\n",
    "    with mp_selfie_segmentation.SelfieSegmentation(model_selection=1) as segmentor:\n",
    "        results_segmentation = segmentor.process(img_rgb)\n",
    "        if results_segmentation.segmentation_mask is not None:\n",
    "            person_mask = (results_segmentation.segmentation_mask > 0.5).astype(np.uint8) * 255\n",
    "            blurred_outline = cv2.GaussianBlur(person_mask, (61,61), 0)\n",
    "            edges = cv2.Canny(blurred_outline, 10, 50)\n",
    "            edges = cv2.dilate(edges, np.ones((5,5),np.uint8), iterations=1)\n",
    "            inverted = cv2.bitwise_not(edges)\n",
    "            final_line_drawing = np.minimum(final_line_drawing, inverted)\n",
    "\n",
    "    # Optional dedicated hair model\n",
    "    if HAIR_MODEL_PATH:\n",
    "        try:\n",
    "            base_options = python.BaseOptions(model_asset_path=HAIR_MODEL_PATH, delegate=None)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_rgb)\n",
    "            options = vision.ImageSegmenterOptions(\n",
    "                base_options=base_options,\n",
    "                running_mode=vision.RunningMode.IMAGE,\n",
    "                output_category_mask=True\n",
    "            )\n",
    "            with vision.ImageSegmenter.create_from_options(options) as segmenter:\n",
    "                segmentation_result = segmenter.segment(mp_image)\n",
    "                category_mask = segmentation_result.category_mask.numpy_view()\n",
    "                hair_mask = np.where(category_mask == 1, 255, 0).astype(np.uint8)\n",
    "                hair_mask = cv2.resize(hair_mask, (W,H), interpolation=cv2.INTER_NEAREST)\n",
    "                blurred_hair = cv2.GaussianBlur(hair_mask, (41,41),0)\n",
    "                edges = cv2.Canny(blurred_hair,10,50)\n",
    "                edges = cv2.dilate(edges,np.ones((5,5),np.uint8),iterations=1)\n",
    "                inverted = cv2.bitwise_not(edges)\n",
    "                final_line_drawing = np.minimum(final_line_drawing, inverted)\n",
    "        except Exception as e:\n",
    "            print(f\"Hair model error: {e}\")\n",
    "        \n",
    "         # Save output\n",
    "    cv2.imwrite(output_path, final_line_drawing)\n",
    "    print(f\"Saved simplified line drawing to: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_to_minimal_line_drawing_simplified('divija_dhall.png', 'selective_line_drawing_simplified_divija_dhall.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9292eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SegFormer model and processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type', 'reduce_labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running semantic segmentation...\n",
      "Saving shirt outline to: shirt_outline_segformer.png\n",
      "Outline generation complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGE_PATH = \"divija.png\"\n",
    "MODEL_CHECKPOINT = \"mattmdjaga/segformer_b2_clothes\"\n",
    "# Map the label index (found in model config) to the target name\n",
    "# For this specific model, Shirt/Top is often one of the first classes (e.g., 1 or 2).\n",
    "# You may need to inspect the model's id2label mapping for the exact ID.\n",
    "SHIRT_LABEL_ID = 4 # **Adjust this ID based on the model's actual mapping**\n",
    "OUTPUT_OUTLINE_PATH = \"shirt_outline_segformer.png\"\n",
    "OUTLINE_THICKNESS = 2\n",
    "OUTLINE_COLOR = (0, 0, 0) # Black (BGR)\n",
    "BACKGROUND_COLOR = (255, 255, 255) # White (BGR)\n",
    "\n",
    "# --- 1. Load the Model and Processor ---\n",
    "print(\"Loading SegFormer model and processor...\")\n",
    "processor = SegformerImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "# --- 2. Load and Prepare the Image ---\n",
    "image_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "image_cv = cv2.imread(IMAGE_PATH)\n",
    "img_height, img_width, _ = image_cv.shape\n",
    "\n",
    "# --- 3. Run Prediction / Segmentation ---\n",
    "print(\"Running semantic segmentation...\")\n",
    "# Process image and get logits\n",
    "inputs = processor(images=image_pil, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "# ... (lines 33-36 of your script)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# --- 3. Corrected Dimension Handling ---\n",
    "\n",
    "# Outputs.logits shape is typically (1, C, H_model, W_model)\n",
    "# We ensure the batch dimension (1) is present for interpolation\n",
    "logits = outputs.logits.cpu().unsqueeze(0) if outputs.logits.dim() == 3 else outputs.logits.cpu()\n",
    "\n",
    "# Check and fix if the batch dimension was implicitly removed\n",
    "# If logits is just (C, H_model, W_model), we add the batch dimension.\n",
    "if logits.dim() == 3:\n",
    "    logits = logits.unsqueeze(0)\n",
    "    \n",
    "# Interpolate expects (N, C, H_model, W_model) and resizes to (N, C, H_img, W_img)\n",
    "upsampled_logits = torch.nn.functional.interpolate(\n",
    "    logits,\n",
    "    size=(img_height, img_width),\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False\n",
    ")\n",
    "\n",
    "# Get the predicted class index (ID) for each pixel.\n",
    "# pred_mask will be (H_img, W_img)\n",
    "pred_mask = upsampled_logits.squeeze(0).argmax(0)\n",
    "# ... (rest of your script continues from here)\n",
    "# --- 4. Extract Shirt Mask and Draw Outline ---\n",
    "# Create a binary mask: 1 where pixel class = SHIRT_LABEL_ID, 0 everywhere else\n",
    "shirt_mask = (pred_mask == SHIRT_LABEL_ID).numpy().astype(np.uint8) * 255 \n",
    "\n",
    "if np.sum(shirt_mask) == 0:\n",
    "    print(\"No shirt found based on the SegFormer model's class ID.\")\n",
    "    outline_image = np.full((img_height, img_width, 3), BACKGROUND_COLOR, dtype=np.uint8)\n",
    "else:\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(shirt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create white background image\n",
    "    outline_image = np.full((img_height, img_width, 3), BACKGROUND_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Draw all found contours\n",
    "    cv2.drawContours(outline_image, contours, -1, OUTLINE_COLOR, OUTLINE_THICKNESS)\n",
    "\n",
    "# --- 5. Save the Output ---\n",
    "print(f\"Saving shirt outline to: {OUTPUT_OUTLINE_PATH}\")\n",
    "cv2.imwrite(OUTPUT_OUTLINE_PATH, shirt_mask)\n",
    "print(\"Outline generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293baca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carlab (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
